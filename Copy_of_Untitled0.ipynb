{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Untitled0.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMP44QQRzBWbS4HJy4DKDi4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LauraSchellekens/TM10007_-private_-group/blob/Laura_random_forest/Copy_of_Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fm5wWUytvpIo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 262
        },
        "outputId": "e3e62d59-0617-433e-8c19-2b211fe8ecfe"
      },
      "source": [
        "# toepassen random forest op onze data \n",
        "\n",
        "# Run this to use from colab environment\n",
        "!pip install -q --upgrade git+https://github.com/karinvangarderen/tm10007_project.git\n",
        "!pip install sklearn numpy matplotlib\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  Building wheel for brats (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.6/dist-packages (0.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (1.18.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (3.2.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sklearn) (0.22.2.post1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.4.6)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (1.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.8.1)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (0.14.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from cycler>=0.10->matplotlib) (1.12.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib) (46.0.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z4Gg5mvezfIR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# General packages\n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn import metrics\n",
        "from sklearn import model_selection"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Y03dVfNzjPl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Data loading functions. Uncomment the one you want to use\n",
        "from adni.load_data import load_data\n",
        "data = load_data()\n",
        "print(f'The number of samples: {len(data.index)}')\n",
        "print(f'The number of columns: {len(data.columns)}')\n",
        "Y = data['label'] \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gfI6hZMeznxo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# defining classifier \n",
        "\n",
        "clf.fit(X, Y)\n",
        "y_pred = clf.predict(X)\n",
        "t = (\"Misclassified: %d / %d\" % ((Y != y_pred).sum(), X.shape[0]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z6T9bnKiMFO0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Grid search in cross validation setting\n",
        "\n",
        "# Create a 20 fold stratified CV iterator\n",
        "cv_20fold = model_selection.StratifiedKFold(n_splits=10)\n",
        "results = []\n",
        "best_n_trees = []\n",
        "\n",
        "# Loop over the folds\n",
        "for validation_index, test_index in cv_20fold.split(X, y) #split in training and test data \n",
        "\n",
        "    # Split the data properly\n",
        "    X_validation = X2[validation_index]\n",
        "    y_validation = y2[validation_index]\n",
        "    \n",
        "    X_test = X2[test_index]\n",
        "    y_test = y2[test_index]\n",
        "\n",
        "    # Create a grid search to find the optimal k using a gridsearch and 10-fold cross validation\n",
        "    parameters = {\"n_trees\": list(range(1, 26, 2))} # range moet gekozen worden \n",
        "    rfc = RandomForestClassifier() \n",
        "    cv_10fold = model_selection.StratifiedKFold(n_splits=10) # folds moet gekozen worden en stratification\n",
        "    grid_search = model_selection.GridSearchCV(rfc, parameters, cv=cv_10fold, scoring='roc_auc') #scoring moet gekozen worden\n",
        "    grid_search.fit(X_validation, y_validation)\n",
        "\n",
        "    # Get resulting classifier\n",
        "    clf = grid_search.best_estimator_\n",
        "    print(f'Best classifier: k={clf.n_estimators}')\n",
        "    best_n_trees.append(clf.n_estimators)\n",
        "\n",
        "    # Test the classifier on the test data\n",
        "    probabilities = clf.predict_proba(X_test)\n",
        "    scores = probabilities[:, 1]\n",
        "    \n",
        "    # Get the auc\n",
        "    auc_validation = metrics.roc_auc_score(y_validation, scores_validation)\n",
        "    results.append({\n",
        "        'auc': auc_validation,\n",
        "        'k': clf.n_neighbors,\n",
        "        'set': 'validation'\n",
        "    })\n",
        "\n",
        "# Create results dataframe and plot it\n",
        "results = pd.DataFrame(results)\n",
        "seaborn.boxplot(y='auc', x='set', data=results)\n",
        "\n",
        "optimal_n = int(np.mean(best_n_trees)) # of median\n",
        "print(f\"The optimal N={optimal_n}\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zf-yijMx4zT_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# scoring classifier   \n",
        "    auc=metrics.roc_auc_score(Y_r, y_score)\n",
        "    accuracy=metrics.accuracy_score(Y_r, y_pred)\n",
        "    F1=metrics.f1_score(Y_r,y_pred)\n",
        "    precision=metrics.precision_score(Y_r,y_pred)\n",
        "    recall=metrics.recall_score(Y_r, y_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}