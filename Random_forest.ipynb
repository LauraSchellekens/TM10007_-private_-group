{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Copy of Untitled0.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPJzy+qarBJThw/TPJArytA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LauraSchellekens/TM10007_-private_-group/blob/Laura_random_forest/Random_forest.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fm5wWUytvpIo",
        "colab_type": "code",
        "outputId": "66d04fda-6769-43ed-f9a3-1d2a50b679cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        }
      },
      "source": [
        "# toepassen random forest op onze data \n",
        "\n",
        "# Run this to use from colab environment\n",
        "!pip install -q --upgrade git+https://github.com/karinvangarderen/tm10007_project.git\n",
        "!pip install sklearn numpy matplotlib\n"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  Building wheel for brats (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.6/dist-packages (0.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (1.18.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (3.2.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sklearn) (0.22.2.post1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.8.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (1.2.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.4.6)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (0.14.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from cycler>=0.10->matplotlib) (1.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z4Gg5mvezfIR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# General packages\n",
        "import numpy as np \n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import impute\n",
        "from sklearn import preprocessing"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Y03dVfNzjPl",
        "colab_type": "code",
        "outputId": "7af50384-e428-407d-8a17-e5b9fc77ea23",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        }
      },
      "source": [
        "# Data loading functions. \n",
        "from adni.load_data import load_data\n",
        "data = load_data()\n",
        "print(f'The number of samples: {len(data.index)}')\n",
        "print(f'The number of columns: {len(data.columns)}')\n",
        "X = data.drop('label', axis=1) # All data without column 'label'\n",
        "Y = data['label'] # AD en CN moeten alleen nog omgezet worden naar 0 en 1\n",
        "Y.replace(('AD', 'CN'), (0, 1), inplace=True) # AD en CN omgezet naar 0 en 1\n",
        "print(\"number of AD patients:\")\n",
        "print((list(data['label'] == 0)).count(True)) # displays number AD patients\n",
        "print(\"number of CN patients:\")\n",
        "print((list(data['label'] == 0)).count(False)) # displays number of CN patients "
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ERROR! Session/line number was not unique in database. History logging moved to new session 59\n",
            "The number of samples: 855\n",
            "The number of columns: 268\n",
            "number of AD patients:\n",
            "519\n",
            "number of CN patients:\n",
            "336\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qIOEJw4pEO25",
        "colab_type": "code",
        "outputId": "c9da8f68-0d55-4337-b4ac-fcbbf535124f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# split into train (70%) and test (30%) set\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3)\n",
        "\n",
        "print (X_train.shape, y_train.shape)\n",
        "print (X_test.shape, y_test.shape)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(598, 267) (598,)\n",
            "(257, 267) (257,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eq0AESGyEMNQ",
        "colab_type": "code",
        "outputId": "ebdd2b38-9aaa-445e-9b25-f53dc13f199d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# Preprocessing: drop feature if too many missing values\n",
        "\n",
        "X_train = X_train.replace(0, np.NaN)                  # replace 0 with NaN\n",
        "missing_per_feature = X_train.isnull().sum()          # gives the amount of missing values (NaN) per feature\n",
        "pct_null = missing_per_feature / len(X_train)         # gives percentage of missing values per feature\n",
        "missing_features = pct_null[pct_null > 0.40].index    # gives features with more than 40% missing values\n",
        "X_train.drop(missing_features, axis=1, inplace=True)  # remove feature if more than 40% missing values\n",
        "\n",
        "missing_per_feature_max = max(X_train.isnull().sum()) # gives the maximum amount of missing values (NaN) per feature AFTER dropping incomplete features\n",
        "\n",
        "print(missing_per_feature_max)\n",
        "print (X_train.shape, y_train.shape)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "97\n",
            "(598, 261) (598,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IVpBxuzSq6_b",
        "colab_type": "code",
        "outputId": "076f7909-231c-4f40-ab85-3d8ccdc332c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# nu ook voor X_test\n",
        "X_test = X_test.replace(0, np.NaN)                  # replace 0 with NaN\n",
        "missing_per_feature = X_test.isnull().sum()          # gives the amount of missing values (NaN) per feature\n",
        "pct_null = missing_per_feature / len(X_test)         # gives percentage of missing values per feature\n",
        "missing_features = pct_null[pct_null > 0.40].index    # gives features with more than 40% missing values\n",
        "X_test.drop(missing_features, axis=1, inplace=True)  # remove feature if more than 40% missing values\n",
        "\n",
        "missing_per_feature_max = max(X_test.isnull().sum()) # gives the maximum amount of missing values (NaN) per feature AFTER dropping incomplete features\n",
        "\n",
        "print(missing_per_feature_max)\n",
        "print (X_test.shape, y_test.shape)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "43\n",
            "(257, 261) (257,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_XtnG4mEVLN",
        "colab_type": "code",
        "outputId": "14571f7d-84f2-4bfe-d324-09e26f8c7fc1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Preprocessing:  impute missing values (fill missing)\n",
        "\n",
        "imputer = impute.SimpleImputer(strategy='mean')     # imputer with mean \n",
        "X_train_imp = imputer.fit_transform(X_train)          # impute  \n",
        "X_train_imp = pd.DataFrame(data=X_train_imp, index=[X_train.index], columns=[X_train.columns]) # turn created np.array back to pandas df\n",
        "\n",
        "type(X_train_imp)\n",
        "\n",
        "# en nu ook voor x_test\n",
        "imputer = impute.SimpleImputer(strategy='mean')     # imputer with mean \n",
        "X_test_imp = imputer.fit_transform(X_test)          # impute  \n",
        "X_test_imp = pd.DataFrame(data=X_test_imp, index=[X_test.index], columns=[X_test.columns]) # turn created np.array back to pandas df\n",
        "\n",
        "type(X_test_imp)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pandas.core.frame.DataFrame"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cNbXgOOKEX7x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Preprocessing: scaling either standard or robust (removes median and scales data according to quantile range) \n",
        "\n",
        "scaler = preprocessing.StandardScaler()\n",
        "scaler.fit_transform(X_train_imp)\n",
        "X_train_scaled = scaler.transform(X_train_imp)\n",
        "# robust = preprocessing.RobustScaler()\n",
        "# robust.fit_transform(X_train_imp)\n",
        "# X_train_scaled = robust.transform(X_train_imp)\n",
        "\n",
        "X_train_scaled = pd.DataFrame(data=X_train_scaled, index=[X_train.index], columns=[X_train.columns]) # turn created np.array back to pandas df\n",
        "\n",
        "# nu ook voor X_TEST\n",
        "scaler = preprocessing.StandardScaler()\n",
        "scaler.fit_transform(X_test_imp)\n",
        "X_test_scaled = scaler.transform(X_test_imp)\n",
        "# robust = preprocessing.RobustScaler()\n",
        "# robust.fit_transform(X_train_imp)\n",
        "# X_train_scaled = robust.transform(X_train_imp)\n",
        "\n",
        "X_test_scaled = pd.DataFrame(data=X_test_scaled, index=[X_test.index], columns=[X_test.columns]) # turn created np.array back to pandas df\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z6T9bnKiMFO0",
        "colab_type": "code",
        "outputId": "e5b522e7-8285-4dd5-e3f5-18f579295b53",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "# Grid search in cross validation setting\n",
        "\n",
        "# Create a 20 fold stratified CV iterator\n",
        "#cv_20fold = model_selection.StratifiedKFold(n_splits=10)\n",
        "results = []\n",
        "best_n_trees = []\n",
        "\n",
        "# Loop over the folds\n",
        "#for train_index, validation_index in cv_20fold.split(X, Y): #split train data in training and validation data\n",
        "\n",
        "    # Split the data properly\n",
        "    #X_train = X[train_index]\n",
        "    #y_train = Y[train_index]\n",
        "    \n",
        "    #X_validation = X[validation_index]\n",
        "    #y_validation = Y[validation_index]\n",
        "\n",
        "# Create a grid search to find the optimal k using a gridsearch and 10-fold cross validation\n",
        "parameters = {\"n_estimators\": list(range(1, 26, 2))} # range moet gekozen worden \n",
        "rfc = RandomForestClassifier() \n",
        "# cv_10fold = model_selection.StratifiedKFold(n_splits=10) # folds moet gekozen worden en stratification\n",
        "grid_search = GridSearchCV(rfc, parameters, scoring='roc_auc') #scoring moet gekozen worden\n",
        "grid_search.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Get resulting classifier\n",
        "clf = grid_search.best_estimator_\n",
        "print(f'Best classifier: k={clf.n_estimators}')\n",
        "#best_n_trees.append(clf.n_estimators)\n",
        "print(best_n_trees)\n",
        "#results.append(grid_search.cv_results_) #mean_test_score\n",
        "#print(results)\n",
        "score= grid_search.best_score_\n",
        "print(score)\n",
        "\n",
        "# Test the classifier on the test data\n",
        "#probabilities = clf.predict_proba(X_validation)\n",
        "#scores = probabilities[:, 1]\n",
        "      \n",
        "# Get the auc\n",
        "#auc_validation = metrics.roc_auc_score(y_validation, scores)\n",
        "#results.append({\n",
        "#'auc': auc_validation, \n",
        "#'k': clf.n_estimators,\n",
        "#'set': 'validation'\n",
        "      #})\n",
        "\n",
        "# Create results dataframe and plot it\n",
        "#results = pd.DataFrame(results)\n",
        "#seaborn.boxplot(y='auc', x='set', data=results)\n",
        "\n",
        "#optimal_n = int(np.median(best_n_trees)) # of median\n",
        "#print(f\"The optimal N={optimal_n}\")"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best classifier: k=5\n",
            "[]\n",
            "0.5445946716551687\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iQA6HrsBrL1w",
        "colab_type": "code",
        "outputId": "aa77accf-b28b-4b66-b398-5852d1a4f9bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "# Use the optimal parameters without any tuning to validate the optimal classifier\n",
        "#clf = RandomForestClassifier(n_estimators=optimal_n)\n",
        "#clf.fit(X, Y)\n",
        "#y_pred = clf.predict(X)\n",
        "#t = (\"Misclassified: %d / %d\" % ((Y != y_pred).sum(), X.shape[0]))\n",
        "\n",
        "# test data \n",
        "y_true, y_pred = y_test, clf.predict(X_test_scaled)\n",
        "auc=metrics.roc_auc_score(y_true, y_pred)\n",
        "print(f'AUC:{auc}')\n",
        "accuracy=metrics.accuracy_score(y_true, y_pred)\n",
        "print(f'accuracy:{auc}')\n",
        "F1=metrics.f1_score(y_true,y_pred)\n",
        "print(f'F1:{auc}')\n",
        "precision=metrics.precision_score(y_true,y_pred)\n",
        "print(f'precision:{auc}')\n",
        "recall=metrics.recall_score(y_true, y_pred)\n",
        "print(f'recall:{auc}')"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AUC:0.42246240601503754\n",
            "accuracy:0.42246240601503754\n",
            "F1:0.42246240601503754\n",
            "precision:0.42246240601503754\n",
            "recall:0.42246240601503754\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zf-yijMx4zT_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# scoring classifier   \n",
        "    auc=metrics.roc_auc_score(Y_r, y_score)\n",
        "    accuracy=metrics.accuracy_score(Y_r, y_pred)\n",
        "    F1=metrics.f1_score(Y_r,y_pred)\n",
        "    precision=metrics.precision_score(Y_r,y_pred)\n",
        "    recall=metrics.recall_score(Y_r, y_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}