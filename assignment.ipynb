{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "assignment.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LauraSchellekens/TM10007_-private_-group/blob/master/assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7SXpaKwwGe5x"
      },
      "source": [
        "# TM10007 Assignment template"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CiDn2Sk-VWqE",
        "outputId": "7f504c20-8699-4e7a-e0c0-f4057c5052fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "# Run this to use from colab environment\n",
        "!pip install -q --upgrade git+https://github.com/karinvangarderen/tm10007_project.git\n",
        "!pip install sklearn numpy matplotlib\n"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  Building wheel for brats (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.6/dist-packages (0.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (1.18.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (3.2.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sklearn) (0.22.2.post1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.4.6)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (1.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.8.1)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (0.14.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from cycler>=0.10->matplotlib) (1.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g4RSrpn64xBB",
        "colab_type": "text"
      },
      "source": [
        "## Data loading and cleaning\n",
        "\n",
        "Below are functions to load the dataset of your choice. After that, it is all up to you to create and evaluate a classification method. Beware, there may be missing values in these datasets. Good luck!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vfEM3ZrBFslw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# General packages not sure anymore what I'm actually using lol\n",
        "import numpy as np \n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "from sklearn import svm\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn import metrics\n",
        "from sklearn import model_selection\n",
        "from sklearn import preprocessing\n",
        "from sklearn import impute\n",
        "from sklearn import datasets, linear_model\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import feature_selection\n",
        "\n",
        "# General packages\n",
        "import numpy as np \n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn import metrics\n",
        "from sklearn import model_selection\n",
        "from sklearn import preprocessing\n",
        "from sklearn import impute\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "from sklearn import datasets, linear_model\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import datasets as ds\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "\n",
        "# import classifier SVC\n",
        "from sklearn.svm import SVC"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-NE_fTbKGe5z",
        "outputId": "2c076419-43f9-4b2a-93b1-f24b9262848c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "# Data loading functions. Uncomment the one you want to use\n",
        "from adni.load_data import load_data\n",
        "\n",
        "data = load_data()\n",
        "print(f'The number of samples: {len(data.index)}')\n",
        "print(f'The number of columns: {len(data.columns)}')\n",
        "\n",
        "\n",
        "X = data.drop('label', axis=1) # All data without column 'label'\n",
        "Y = data['label'] \n",
        "Y.replace(('AD', 'CN'), (1, 0), inplace=True) # convert AD and CN to 1 and 0\n"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The number of samples: 855\n",
            "The number of columns: 268\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ALV9F1WaFky5",
        "colab_type": "code",
        "outputId": "43f9ff34-ecd7-42b0-9ac5-5f8d7f4a31b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "# split into train (70%) and test (30%) set\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3)\n",
        "\n",
        "print (X_train.shape, y_train.shape)\n",
        "print (X_test.shape, y_test.shape)\n"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(598, 267) (598,)\n",
            "(257, 267) (257,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bhzsIpDZF1lc",
        "colab_type": "code",
        "outputId": "7248ab41-9e5a-48c9-f67a-1b0a7ac709c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "# Preprocessing: drop feature if too many missing values\n",
        "\n",
        "X_train = X_train.replace(0, np.NaN)                                    # replace 0 with NaN\n",
        "missing_per_feature_train = X_train.isnull().sum()                      # gives the amount of missing values (NaN) per feature\n",
        "pct_null_train = missing_per_feature_train / len(X_train)               # gives percentage of missing values per feature\n",
        "missing_features_train = pct_null_train[pct_null_train > 0.40].index    # gives features with more than 40% missing values\n",
        "X_train.drop(missing_features_train, axis=1, inplace=True)              # remove feature if more than 40% missing values\n",
        "\n",
        "X_test = X_test.replace(0, np.NaN)                                      # replace 0 with NaN\n",
        "missing_per_feature_test = X_test.isnull().sum()                        # gives the amount of missing values (NaN) per feature\n",
        "pct_null_test = missing_per_feature_test / len(X_test)                  # gives percentage of missing values per feature\n",
        "missing_features_test = pct_null_test[pct_null_train > 0.40].index      # gives features with more than 40% missing values\n",
        "X_test.drop(missing_features_test, axis=1, inplace=True)                # remove feature if more than 40% missing values\n",
        "\n",
        "missing_per_feature_max_train = max(X_train.isnull().sum())             # gives the maximum amount of missing values (NaN) per feature AFTER dropping incomplete features\n",
        "missing_per_feature_max_test = max(X_test.isnull().sum())               # gives the maximum amount of missing values (NaN) per feature AFTER dropping incomplete features\n",
        "\n",
        "print(missing_per_feature_max)\n",
        "print (X_train.shape, y_train.shape)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "94\n",
            "(598, 261) (598,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bF5N3yD9qTOT",
        "colab_type": "code",
        "outputId": "75cd7d20-70ce-4893-a860-f405b1510de4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Preprocessing:  impute missing values (fill missing)\n",
        "\n",
        "imputer = impute.SimpleImputer(strategy='mean')       # imputer with mean \n",
        "X_train_imp = imputer.fit_transform(X_train)          # impute  \n",
        "X_train_imp = pd.DataFrame(data=X_train_imp, index=[X_train.index], columns=[X_train.columns])  # turn created np.array back to pandas df\n",
        "\n",
        "X_test_imp = imputer.fit_transform(X_test)            # impute  \n",
        "X_test_imp = pd.DataFrame(data=X_test_imp, index=[X_test.index], columns=[X_test.columns])      # turn created np.array back to pandas df\n",
        "\n",
        "type(X_train_imp)\n"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pandas.core.frame.DataFrame"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQq8pxCrwUxk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Preprocessing: scaling either standard or robust (removes median and scales data according to quantile range) \n",
        "\n",
        "scaler = preprocessing.StandardScaler()\n",
        "scaler.fit_transform(X_train_imp)\n",
        "X_train_scaled = scaler.transform(X_train_imp)        # scaling the training data\n",
        "\n",
        "scaler.fit_transform(X_test_imp)\n",
        "X_test_scaled = scaler.transform(X_test_imp)          # scaling the test data\n",
        "\n",
        "X_train_scaled = pd.DataFrame(data=X_train_scaled, index=[X_train.index], columns=[X_train.columns])  # turn created np.array back to pandas df\n",
        "X_test_scaled = pd.DataFrame(data=X_test_scaled, index=[X_test.index], columns=[X_test.columns])      # turn created np.array back to pandas df\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TsmToGZ2IdnL",
        "colab_type": "code",
        "outputId": "f27e1182-1bbb-4b0a-f618-acd07954925f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        }
      },
      "source": [
        "# Code for feature selection\n",
        "'''\n",
        "First determine the best amount of features\n",
        "'''\n",
        "\n",
        "# Create the RFE object and compute a cross-validated score.\n",
        "svc = svm.SVC(kernel=\"linear\")\n",
        "X= X_train_scaled.iloc[:,1:261]\n",
        "y= y_train\n",
        "\n",
        "# classifications\n",
        "rfecv = feature_selection.RFECV(\n",
        "    estimator=svc, step=1, \n",
        "    cv=model_selection.StratifiedKFold(4),\n",
        "    scoring='roc_auc')\n",
        "rfecv.fit(X, y)\n",
        "\n",
        "# Plot number of features VS. cross-validation scores\n",
        "plt.figure()\n",
        "plt.xlabel(\"Number of features selected\")\n",
        "plt.ylabel(\"Cross validation score (nb of correct classifications)\")\n",
        "plt.plot(range(1, len(rfecv.grid_scores_) + 1), rfecv.grid_scores_)\n",
        "plt.show()\n"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEaCAYAAAAL7cBuAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nsoNIkiRJSvk33Oh7QVb/Fh0AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6wZSGsffig8o",
        "colab_type": "code",
        "outputId": "dfc07e90-4331-4902-d8e4-0b90b8c69031",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 658
        }
      },
      "source": [
        "# Code for feature selection\n",
        "'''\n",
        "With the amount of features desired known, find the best performing features\n",
        "'''\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import f_classif\n",
        " \n",
        "#apply SelectKBest class to extract top ... best features\n",
        "bestfeatures = SelectKBest(score_func= f_classif, k=32) # k= number of desired features\n",
        "fit = bestfeatures.fit(X,y)\n",
        "dfscores = pd.DataFrame(fit.scores_)\n",
        "dfcolumns = pd.DataFrame(X.columns)\n",
        "#concat two dataframes for better visualization \n",
        "featureScores = pd.concat([dfcolumns,dfscores],axis=1)\n",
        "featureScores.columns = ['Specs','Score']  #naming the dataframe columns\n",
        "print(featureScores.nlargest(32,'Score'))  #print ... best features "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                            Specs       Score\n",
            "0                                   (hf_entropy,)  427.427213\n",
            "217                          (tf_LBP_std_R3_P12,)  334.302007\n",
            "1                                  (hf_kurtosis,)  334.233558\n",
            "7                            (hf_quartile_range,)  319.800005\n",
            "10                                      (hf_std,)  290.500809\n",
            "110                  (tf_GLRLM_ShortRunEmphasis,)  236.059742\n",
            "99                  (tf_GLRLM_GrayLevelVariance,)  231.468762\n",
            "98   (tf_GLRLM_GrayLevelNonUniformityNormalized,)  226.803663\n",
            "112      (tf_GLRLM_ShortRunLowGrayLevelEmphasis,)  225.566689\n",
            "72              (phasef_phasesym_entropy_WL3_N5,)  202.821690\n",
            "133                      (tf_Gabor_0.05A0.0skew,)  180.773030\n",
            "108                     (tf_GLRLM_RunPercentage,)  173.191494\n",
            "5                                       (hf_min,)  160.641596\n",
            "101                   (tf_GLRLM_LongRunEmphasis,)  158.384793\n",
            "202                     (tf_LBP_kurtosis_R3_P12,)  154.227872\n",
            "75                 (phasef_phasesym_mean_WL3_N5,)  152.775108\n",
            "106            (tf_GLRLM_RunLengthNonUniformity,)  145.208858\n",
            "78             (phasef_phasesym_skewness_WL3_N5,)  144.720967\n",
            "149                     (tf_Gabor_0.05A2.36mean,)  142.300490\n",
            "79                  (phasef_phasesym_std_WL3_N5,)  138.900011\n",
            "8                                     (hf_range,)  138.697948\n",
            "138                      (tf_Gabor_0.05A0.79min,)  136.815268\n",
            "136                      (tf_Gabor_0.05A0.79max,)  131.372042\n",
            "74                  (phasef_phasesym_max_WL3_N5,)  129.372978\n",
            "77                (phasef_phasesym_range_WL3_N5,)  129.372978\n",
            "154                        (tf_Gabor_0.2A0.0max,)  129.075343\n",
            "107  (tf_GLRLM_RunLengthNonUniformityNormalized,)  122.988680\n",
            "161                      (tf_Gabor_0.2A0.79mean,)  122.141871\n",
            "141                     (tf_Gabor_0.05A1.57kurt,)  116.225170\n",
            "158                        (tf_Gabor_0.2A0.0std,)  113.279741\n",
            "153                       (tf_Gabor_0.2A0.0kurt,)  112.503449\n",
            "142                      (tf_Gabor_0.05A1.57max,)  110.258146\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/_univariate_selection.py:114: UserWarning: Features [207 210 211 212] are constant.\n",
            "  UserWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/_univariate_selection.py:115: RuntimeWarning: invalid value encountered in true_divide\n",
            "  f = msb / msw\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4GWUil5e___A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 823
        },
        "outputId": "6bf18f01-bfaa-43c3-e6ed-0129d34c4088"
      },
      "source": [
        "# Random Forest Classifier\n",
        "\n",
        "# Set parameters\n",
        "parameters = {\"n_estimators\": list(range(1, 20, 2))}\n",
        "    # nog een range kiezen\n",
        "\n",
        "scores = ['precision', 'recall']\n",
        "\n",
        "for score in scores:\n",
        "    print('# Random Forest Classifier')\n",
        "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
        "    print()\n",
        "    rfc = RandomForestClassifier()\n",
        "    grid_search = GridSearchCV(\n",
        "        rfc, parameters, scoring='%s_macro' % score\n",
        "    ) \n",
        "    # cv is nu default, dus een kfold van 5! \n",
        "    grid_search.fit(X_train_scaled, y_train)\n",
        "\n",
        "    print(\"Best parameters set found on development set:\")\n",
        "    print()\n",
        "    clf = grid_search.best_estimator_\n",
        "    print(f'Best classifier: k={clf.n_estimators}')\n",
        "    print()\n",
        "    print(\"Grid scores on development set:\")\n",
        "    print()\n",
        "    means = grid_search.cv_results_['mean_test_score']\n",
        "    stds = grid_search.cv_results_['std_test_score']\n",
        "    for mean, std, params in zip(means, stds, grid_search.cv_results_['params']):\n",
        "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
        "              % (mean, std * 2, params))\n",
        "    print()\n",
        "\n",
        "# test data\n",
        "print(\"# Evaluate with test data set\")\n",
        "y_true, y_pred = y_test, clf.predict(X_test_scaled)\n",
        "\n",
        "auc=metrics.roc_auc_score(y_true, y_pred)\n",
        "print(f'AUC:{auc}')\n",
        "accuracy=metrics.accuracy_score(y_true, y_pred)\n",
        "print(f'accuracy:{auc}')\n",
        "F1=metrics.f1_score(y_true,y_pred)\n",
        "print(f'F1:{auc}')\n",
        "precision=metrics.precision_score(y_true,y_pred)\n",
        "print(f'precision:{auc}')\n",
        "recall=metrics.recall_score(y_true, y_pred)\n",
        "print(f'recall:{auc}')\n"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# Random Forest Classifier\n",
            "# Tuning hyper-parameters for precision\n",
            "\n",
            "Best parameters set found on development set:\n",
            "\n",
            "Best classifier: k=19\n",
            "\n",
            "0.7940381513910927\n",
            "Grid scores on development set:\n",
            "\n",
            "0.730 (+/-0.027) for {'n_estimators': 1}\n",
            "0.742 (+/-0.058) for {'n_estimators': 3}\n",
            "0.757 (+/-0.060) for {'n_estimators': 5}\n",
            "0.778 (+/-0.040) for {'n_estimators': 7}\n",
            "0.786 (+/-0.066) for {'n_estimators': 9}\n",
            "0.791 (+/-0.084) for {'n_estimators': 11}\n",
            "0.773 (+/-0.015) for {'n_estimators': 13}\n",
            "0.785 (+/-0.089) for {'n_estimators': 15}\n",
            "0.780 (+/-0.064) for {'n_estimators': 17}\n",
            "0.794 (+/-0.073) for {'n_estimators': 19}\n",
            "\n",
            "# Random Forest Classifier\n",
            "# Tuning hyper-parameters for recall\n",
            "\n",
            "Best parameters set found on development set:\n",
            "\n",
            "Best classifier: k=17\n",
            "\n",
            "0.7921969799371178\n",
            "Grid scores on development set:\n",
            "\n",
            "0.714 (+/-0.083) for {'n_estimators': 1}\n",
            "0.735 (+/-0.075) for {'n_estimators': 3}\n",
            "0.762 (+/-0.079) for {'n_estimators': 5}\n",
            "0.732 (+/-0.087) for {'n_estimators': 7}\n",
            "0.779 (+/-0.084) for {'n_estimators': 9}\n",
            "0.772 (+/-0.085) for {'n_estimators': 11}\n",
            "0.783 (+/-0.077) for {'n_estimators': 13}\n",
            "0.776 (+/-0.067) for {'n_estimators': 15}\n",
            "0.792 (+/-0.085) for {'n_estimators': 17}\n",
            "0.768 (+/-0.086) for {'n_estimators': 19}\n",
            "\n",
            "# Evaluate with test data set\n",
            "AUC:0.7624920936116383\n",
            "accuracy:0.7624920936116383\n",
            "F1:0.7624920936116383\n",
            "precision:0.7624920936116383\n",
            "recall:0.7624920936116383\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TuutfCjs6Rjq",
        "colab_type": "code",
        "outputId": "aaf2bdbe-3fcb-4164-d2bb-877ad5ad9897",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 605
        }
      },
      "source": [
        "# Support Vector Machine Classifier\n",
        "\n",
        "# Set parameters\n",
        "parameters = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-2],\n",
        "                     'C': [1, 10]}]\n",
        "\n",
        "scores = ['precision', 'recall']\n",
        "\n",
        "for score in scores:\n",
        "    print('# Support Vector Machine Classifier')\n",
        "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
        "    print()\n",
        "    svc = SVC()\n",
        "    grid_search = GridSearchCV(\n",
        "        svc, parameters, scoring='%s_macro' % score\n",
        "    ) \n",
        "    # cv is nu default, dus een kfold van 5! \n",
        "    grid_search.fit(X_train_scaled, y_train)\n",
        "\n",
        "    print(\"Best parameters set found on development set:\")\n",
        "    print()\n",
        "    clf = grid_search.best_estimator_\n",
        "    best_parameters = grid_search.best_params_\n",
        "    print(best_parameters)\n",
        "    print()\n",
        "    print(\"Grid scores on development set:\")\n",
        "    print()\n",
        "    means = grid_search.cv_results_['mean_test_score']\n",
        "    stds = grid_search.cv_results_['std_test_score']\n",
        "    for mean, std, params in zip(means, stds, grid_search.cv_results_['params']):\n",
        "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
        "              % (mean, std * 2, params))\n",
        "    print()\n",
        "\n",
        "# test data\n",
        "print(\"# Evaluate with test data set\")\n",
        "y_true, y_pred = y_test, clf.predict(X_test_scaled)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Accuracy:{accuracy}')\n",
        "auc=metrics.roc_auc_score(y_test, y_pred)\n",
        "print(f'AUC:{auc}')\n",
        "accuracy=metrics.accuracy_score(y_test, y_pred)\n",
        "print(f'accuracy:{auc}')\n",
        "F1=metrics.f1_score(y_test,y_pred)\n",
        "print(f'F1:{auc}')\n",
        "precision=metrics.precision_score(y_test,y_pred)\n",
        "print(f'precision:{auc}')\n",
        "recall=metrics.recall_score(y_test, y_pred)\n",
        "print(f'recall:{auc}')"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SVM Classifier\n",
            "# Tuning hyper-parameters for precision\n",
            "\n",
            "Best parameters set found on development set:\n",
            "\n",
            "{'C': 1, 'gamma': 0.001, 'kernel': 'rbf'}\n",
            "\n",
            "Grid scores on development set:\n",
            "\n",
            "0.810 (+/-0.081) for {'C': 1, 'gamma': 0.001, 'kernel': 'rbf'}\n",
            "0.793 (+/-0.065) for {'C': 1, 'gamma': 0.01, 'kernel': 'rbf'}\n",
            "0.802 (+/-0.080) for {'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}\n",
            "0.795 (+/-0.070) for {'C': 10, 'gamma': 0.01, 'kernel': 'rbf'}\n",
            "\n",
            "SVM Classifier\n",
            "# Tuning hyper-parameters for recall\n",
            "\n",
            "Best parameters set found on development set:\n",
            "\n",
            "{'C': 1, 'gamma': 0.001, 'kernel': 'rbf'}\n",
            "\n",
            "Grid scores on development set:\n",
            "\n",
            "0.789 (+/-0.094) for {'C': 1, 'gamma': 0.001, 'kernel': 'rbf'}\n",
            "0.769 (+/-0.082) for {'C': 1, 'gamma': 0.01, 'kernel': 'rbf'}\n",
            "0.787 (+/-0.084) for {'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}\n",
            "0.774 (+/-0.089) for {'C': 10, 'gamma': 0.01, 'kernel': 'rbf'}\n",
            "\n",
            "Evaluate with test data set\n",
            "Accuracy:0.7898832684824902\n",
            "AUC:0.7688172043010754\n",
            "accuracy:0.7688172043010754\n",
            "F1:0.7688172043010754\n",
            "precision:0.7688172043010754\n",
            "recall:0.7688172043010754\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SDDcjSKdCSnu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6ed13a69-51c5-4004-e81f-d4c4926fbada"
      },
      "source": [
        "# K Nearest Neighbour Classifier\n",
        "\n",
        "# Set parameters\n",
        "parameters = {\"n_neighbors\": list(range(1, 50, 2))}\n",
        "\n",
        "scores = ['precision', 'recall']\n",
        "\n",
        "for score in scores:\n",
        "    print(\"# K Nearest Neighbour Classifier\")\n",
        "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
        "    print()\n",
        "    knn = KNeighborsClassifier()\n",
        "    grid_search = GridSearchCV(\n",
        "        knn, parameters, scoring='%s_macro' % score\n",
        "    ) \n",
        "    # cv is nu default, dus een kfold van 5! \n",
        "    grid_search.fit(X_train_scaled, y_train)\n",
        "\n",
        "    print(\"Best parameters set found on development set:\")\n",
        "    print()\n",
        "    clf = grid_search.best_estimator_\n",
        "    print(clf)\n",
        "    print()\n",
        "    print(\"Grid scores on development set:\")\n",
        "    print()\n",
        "    means = grid_search.cv_results_['mean_test_score']\n",
        "    stds = grid_search.cv_results_['std_test_score']\n",
        "    for mean, std, params in zip(means, stds, grid_search.cv_results_['params']):\n",
        "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
        "              % (mean, std * 2, params))\n",
        "    print()\n",
        "\n",
        "# test data\n",
        "print('# Evaluate with test data set')\n",
        "y_true, y_pred = y_test, clf.predict(X_test_scaled)\n",
        "\n",
        "auc=metrics.roc_auc_score(y_true, y_pred)\n",
        "print(f'AUC:{auc}')\n",
        "accuracy=metrics.accuracy_score(y_true, y_pred)\n",
        "print(f'accuracy:{auc}')\n",
        "F1=metrics.f1_score(y_true,y_pred)\n",
        "print(f'F1:{auc}')\n",
        "precision=metrics.precision_score(y_true,y_pred)\n",
        "print(f'precision:{auc}')\n",
        "recall=metrics.recall_score(y_true, y_pred)\n",
        "print(f'recall:{auc}')"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# K Nearest Neighbour Classifier\n",
            "# Tuning hyper-parameters for precision\n",
            "\n",
            "Best parameters set found on development set:\n",
            "\n",
            "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
            "                     metric_params=None, n_jobs=None, n_neighbors=27, p=2,\n",
            "                     weights='uniform')\n",
            "\n",
            "Grid scores on development set:\n",
            "\n",
            "0.694 (+/-0.064) for {'n_neighbors': 1}\n",
            "0.744 (+/-0.067) for {'n_neighbors': 3}\n",
            "0.765 (+/-0.055) for {'n_neighbors': 5}\n",
            "0.788 (+/-0.075) for {'n_neighbors': 7}\n",
            "0.795 (+/-0.032) for {'n_neighbors': 9}\n",
            "0.797 (+/-0.041) for {'n_neighbors': 11}\n",
            "0.803 (+/-0.057) for {'n_neighbors': 13}\n",
            "0.789 (+/-0.067) for {'n_neighbors': 15}\n",
            "0.799 (+/-0.048) for {'n_neighbors': 17}\n",
            "0.793 (+/-0.051) for {'n_neighbors': 19}\n",
            "0.803 (+/-0.060) for {'n_neighbors': 21}\n",
            "0.805 (+/-0.043) for {'n_neighbors': 23}\n",
            "0.804 (+/-0.036) for {'n_neighbors': 25}\n",
            "0.807 (+/-0.039) for {'n_neighbors': 27}\n",
            "0.801 (+/-0.061) for {'n_neighbors': 29}\n",
            "0.799 (+/-0.052) for {'n_neighbors': 31}\n",
            "0.799 (+/-0.035) for {'n_neighbors': 33}\n",
            "0.800 (+/-0.052) for {'n_neighbors': 35}\n",
            "0.800 (+/-0.042) for {'n_neighbors': 37}\n",
            "0.800 (+/-0.037) for {'n_neighbors': 39}\n",
            "0.796 (+/-0.050) for {'n_neighbors': 41}\n",
            "0.790 (+/-0.054) for {'n_neighbors': 43}\n",
            "0.794 (+/-0.051) for {'n_neighbors': 45}\n",
            "0.792 (+/-0.044) for {'n_neighbors': 47}\n",
            "0.789 (+/-0.051) for {'n_neighbors': 49}\n",
            "\n",
            "# K Nearest Neighbour Classifier\n",
            "# Tuning hyper-parameters for recall\n",
            "\n",
            "Best parameters set found on development set:\n",
            "\n",
            "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
            "                     metric_params=None, n_jobs=None, n_neighbors=25, p=2,\n",
            "                     weights='uniform')\n",
            "\n",
            "Grid scores on development set:\n",
            "\n",
            "0.696 (+/-0.070) for {'n_neighbors': 1}\n",
            "0.735 (+/-0.077) for {'n_neighbors': 3}\n",
            "0.748 (+/-0.055) for {'n_neighbors': 5}\n",
            "0.768 (+/-0.088) for {'n_neighbors': 7}\n",
            "0.765 (+/-0.063) for {'n_neighbors': 9}\n",
            "0.767 (+/-0.069) for {'n_neighbors': 11}\n",
            "0.772 (+/-0.073) for {'n_neighbors': 13}\n",
            "0.762 (+/-0.084) for {'n_neighbors': 15}\n",
            "0.774 (+/-0.073) for {'n_neighbors': 17}\n",
            "0.765 (+/-0.080) for {'n_neighbors': 19}\n",
            "0.776 (+/-0.086) for {'n_neighbors': 21}\n",
            "0.776 (+/-0.072) for {'n_neighbors': 23}\n",
            "0.777 (+/-0.070) for {'n_neighbors': 25}\n",
            "0.775 (+/-0.072) for {'n_neighbors': 27}\n",
            "0.771 (+/-0.082) for {'n_neighbors': 29}\n",
            "0.767 (+/-0.071) for {'n_neighbors': 31}\n",
            "0.767 (+/-0.059) for {'n_neighbors': 33}\n",
            "0.766 (+/-0.073) for {'n_neighbors': 35}\n",
            "0.763 (+/-0.064) for {'n_neighbors': 37}\n",
            "0.764 (+/-0.061) for {'n_neighbors': 39}\n",
            "0.763 (+/-0.066) for {'n_neighbors': 41}\n",
            "0.754 (+/-0.066) for {'n_neighbors': 43}\n",
            "0.758 (+/-0.066) for {'n_neighbors': 45}\n",
            "0.757 (+/-0.050) for {'n_neighbors': 47}\n",
            "0.752 (+/-0.067) for {'n_neighbors': 49}\n",
            "\n",
            "# Evaluate with test data set\n",
            "AUC:0.7296015180265655\n",
            "accuracy:0.7296015180265655\n",
            "F1:0.7296015180265655\n",
            "precision:0.7296015180265655\n",
            "recall:0.7296015180265655\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}