{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "assignment.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LauraSchellekens/TM10007_-private_-group/blob/master/assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7SXpaKwwGe5x"
      },
      "source": [
        "# TM10007 Assignment template"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CiDn2Sk-VWqE",
        "outputId": "cdf7142c-9f63-49b2-90d0-42b4907d175f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        }
      },
      "source": [
        "# Run this to use from colab environment\n",
        "!pip install -q --upgrade git+https://github.com/karinvangarderen/tm10007_project.git\n",
        "!pip install sklearn numpy matplotlib\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  Building wheel for brats (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.6/dist-packages (0.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (1.18.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (3.2.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sklearn) (0.22.2.post1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (1.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.8.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.4.6)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (0.10.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (0.14.1)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (1.4.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.1->matplotlib) (1.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g4RSrpn64xBB",
        "colab_type": "text"
      },
      "source": [
        "## Data loading and cleaning\n",
        "\n",
        "Below are functions to load the dataset of your choice. After that, it is all up to you to create and evaluate a classification method. Beware, there may be missing values in these datasets. Good luck!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vfEM3ZrBFslw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# General packages not sure anymore what I'm actually using lol\n",
        "import numpy as np \n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "from sklearn import svm\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn import metrics\n",
        "from sklearn import model_selection\n",
        "from sklearn import preprocessing\n",
        "from sklearn import impute\n",
        "from sklearn import datasets, linear_model\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import feature_selection\n",
        "\n",
        "# General packages\n",
        "import numpy as np \n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn import metrics\n",
        "from sklearn import model_selection\n",
        "from sklearn import preprocessing\n",
        "from sklearn import impute\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "from sklearn import datasets, linear_model\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import datasets as ds\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "\n",
        "# import classifier SVC\n",
        "from sklearn.svm import SVC"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-NE_fTbKGe5z",
        "outputId": "20fa6310-1274-47c3-ece3-17b200d1212c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "# Data loading functions. Uncomment the one you want to use\n",
        "from adni.load_data import load_data\n",
        "\n",
        "data = load_data()\n",
        "print(f'The number of samples: {len(data.index)}')\n",
        "print(f'The number of columns: {len(data.columns)}')\n",
        "\n",
        "\n",
        "X = data.drop('label', axis=1) # All data without column 'label'\n",
        "Y = data['label'] \n",
        "Y.replace(('AD', 'CN'), (1, 0), inplace=True) # convert AD and CN to 1 and 0\n",
        "print(\"number of AD patients:\")\n",
        "print((list(data['label'] == 0)).count(True)) # displays number AD patients\n",
        "print(\"number of CN patients:\")\n",
        "print((list(data['label'] == 0)).count(False)) # displays number of CN patients \n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The number of samples: 855\n",
            "The number of columns: 268\n",
            "number of AD patients:\n",
            "336\n",
            "number of CN patients:\n",
            "519\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ALV9F1WaFky5",
        "colab_type": "code",
        "outputId": "016227db-ffdb-445c-a60c-995e24d66d76",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# split into train (70%) and test (30%) set\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3)\n",
        "\n",
        "print (X_train.shape, y_train.shape)\n",
        "print (X_test.shape, y_test.shape)\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(598, 267) (598,)\n",
            "(257, 267) (257,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bhzsIpDZF1lc",
        "colab_type": "code",
        "outputId": "722d4c8a-a236-4fa3-8b70-bc4a52d3fe53",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# Preprocessing: drop feature if too many missing values\n",
        "\n",
        "X_train = X_train.replace(0, np.NaN)                                    # replace 0 with NaN\n",
        "missing_per_feature_train = X_train.isnull().sum()                      # gives the amount of missing values (NaN) per feature\n",
        "pct_null_train = missing_per_feature_train / len(X_train)               # gives percentage of missing values per feature\n",
        "missing_features_train = pct_null_train[pct_null_train > 0.40].index    # gives features with more than 40% missing values\n",
        "X_train.drop(missing_features_train, axis=1, inplace=True)              # remove feature if more than 40% missing values\n",
        "\n",
        "X_test = X_test.replace(0, np.NaN)                                      # replace 0 with NaN\n",
        "missing_per_feature_test = X_test.isnull().sum()                        # gives the amount of missing values (NaN) per feature\n",
        "pct_null_test = missing_per_feature_test / len(X_test)                  # gives percentage of missing values per feature\n",
        "missing_features_test = pct_null_test[pct_null_train > 0.40].index      # gives features with more than 40% missing values\n",
        "X_test.drop(missing_features_test, axis=1, inplace=True)                # remove feature if more than 40% missing values\n",
        "\n",
        "missing_per_feature_max_train = max(X_train.isnull().sum())             # gives the maximum amount of missing values (NaN) per feature AFTER dropping incomplete features\n",
        "missing_per_feature_max_test = max(X_test.isnull().sum())               # gives the maximum amount of missing values (NaN) per feature AFTER dropping incomplete features\n",
        "\n",
        "print(missing_per_feature_max_train)\n",
        "print (X_train.shape, y_train.shape)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "92\n",
            "(598, 261) (598,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bF5N3yD9qTOT",
        "colab_type": "code",
        "outputId": "c0f37a36-c25d-44d3-a246-0eda497455af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Preprocessing:  impute missing values (fill missing)\n",
        "\n",
        "imputer = impute.SimpleImputer(strategy='mean')       # imputer with mean \n",
        "X_train_imp = imputer.fit_transform(X_train)          # impute  \n",
        "X_train_imp = pd.DataFrame(data=X_train_imp, index=[X_train.index], columns=[X_train.columns])  # turn created np.array back to pandas df\n",
        "\n",
        "X_test_imp = imputer.fit_transform(X_test)            # impute  \n",
        "X_test_imp = pd.DataFrame(data=X_test_imp, index=[X_test.index], columns=[X_test.columns])      # turn created np.array back to pandas df\n",
        "\n",
        "type(X_train_imp)\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pandas.core.frame.DataFrame"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQq8pxCrwUxk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b615a45d-3d4e-408c-a185-c5061e2d219e"
      },
      "source": [
        "# Preprocessing: scaling either standard or robust (removes median and scales data according to quantile range) \n",
        "\n",
        "scaler = preprocessing.StandardScaler()\n",
        "scaler.fit_transform(X_train_imp)\n",
        "X_train_scaled = scaler.transform(X_train_imp)        # scaling the training data\n",
        "\n",
        "scaler.fit_transform(X_test_imp)\n",
        "X_test_scaled = scaler.transform(X_test_imp)          # scaling the test data\n",
        "\n",
        "X_train_scaled = pd.DataFrame(data=X_train_scaled, index=[X_train.index], columns=[X_train.columns])  # turn created np.array back to pandas df\n",
        "X_test_scaled = pd.DataFrame(data=X_test_scaled, index=[X_test.index], columns=[X_test.columns])      # turn created np.array back to pandas df\n",
        "\n",
        "print(len(X_train_scaled))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "598\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TsmToGZ2IdnL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Code for greedy feature selection through backward feature elimination\n",
        "'''\n",
        "First determine the best amount of features\n",
        "'''\n",
        "\n",
        "# Create the RFE object and compute a cross-validated score.\n",
        "svc = svm.SVC(kernel=\"linear\", random_state=None)\n",
        "X_length = len(X_train_scaled) #morgen nog even checken of t zo kan\n",
        "X= X_train_scaled.iloc[:,1:261]\n",
        "y= y_train\n",
        "\n",
        "# classifications\n",
        "rfecv = feature_selection.RFECV(estimator=svc,step=1,cv=model_selection.StratifiedKFold(5),scoring='roc_auc')\n",
        "rfecv.fit_transform(X,y)\n",
        "\n",
        "\n",
        "\n",
        "# Plot number of features VS. cross-validation scores\n",
        "plt.figure()\n",
        "plt.xlabel(\"Number of features selected\")\n",
        "plt.ylabel(\"Cross validation score (nb of correct classifications)\")\n",
        "plt.plot(range(1, len(rfecv.grid_scores_) + 1), rfecv.grid_scores_)\n",
        "plt.show()\n",
        "\n",
        "# Print score and df of selected features\n",
        "score = rfecv.score(X, y)\n",
        "bestfeatures = rfecv.get_support(True)\n",
        "XX= X_train_scaled.iloc[:,bestfeatures]\n",
        "print('------------------------')\n",
        "print(score)\n",
        "print(bestfeatures)\n",
        "XX\n",
        "# rfecv.support_\n",
        "# print(len(rfecv.ranking_))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dGqd4rwE8Rtd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6wZSGsffig8o",
        "colab_type": "code",
        "outputId": "dfc07e90-4331-4902-d8e4-0b90b8c69031",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 658
        }
      },
      "source": [
        "# Code for feature selection\n",
        "'''\n",
        "With the amount of features desired known, find the best performing features\n",
        "'''\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import f_classif\n",
        " \n",
        "#apply SelectKBest class to extract top ... best features\n",
        "bestfeatures = SelectKBest(score_func= f_classif, k=32) # k= number of desired features\n",
        "fit = bestfeatures.fit(X,y)\n",
        "dfscores = pd.DataFrame(fit.scores_)\n",
        "dfcolumns = pd.DataFrame(X.columns)\n",
        "#concat two dataframes for better visualization \n",
        "featureScores = pd.concat([dfcolumns,dfscores],axis=1)\n",
        "featureScores.columns = ['Specs','Score']  #naming the dataframe columns\n",
        "print(featureScores.nlargest(32,'Score'))  #print ... best features "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                            Specs       Score\n",
            "0                                   (hf_entropy,)  427.427213\n",
            "217                          (tf_LBP_std_R3_P12,)  334.302007\n",
            "1                                  (hf_kurtosis,)  334.233558\n",
            "7                            (hf_quartile_range,)  319.800005\n",
            "10                                      (hf_std,)  290.500809\n",
            "110                  (tf_GLRLM_ShortRunEmphasis,)  236.059742\n",
            "99                  (tf_GLRLM_GrayLevelVariance,)  231.468762\n",
            "98   (tf_GLRLM_GrayLevelNonUniformityNormalized,)  226.803663\n",
            "112      (tf_GLRLM_ShortRunLowGrayLevelEmphasis,)  225.566689\n",
            "72              (phasef_phasesym_entropy_WL3_N5,)  202.821690\n",
            "133                      (tf_Gabor_0.05A0.0skew,)  180.773030\n",
            "108                     (tf_GLRLM_RunPercentage,)  173.191494\n",
            "5                                       (hf_min,)  160.641596\n",
            "101                   (tf_GLRLM_LongRunEmphasis,)  158.384793\n",
            "202                     (tf_LBP_kurtosis_R3_P12,)  154.227872\n",
            "75                 (phasef_phasesym_mean_WL3_N5,)  152.775108\n",
            "106            (tf_GLRLM_RunLengthNonUniformity,)  145.208858\n",
            "78             (phasef_phasesym_skewness_WL3_N5,)  144.720967\n",
            "149                     (tf_Gabor_0.05A2.36mean,)  142.300490\n",
            "79                  (phasef_phasesym_std_WL3_N5,)  138.900011\n",
            "8                                     (hf_range,)  138.697948\n",
            "138                      (tf_Gabor_0.05A0.79min,)  136.815268\n",
            "136                      (tf_Gabor_0.05A0.79max,)  131.372042\n",
            "74                  (phasef_phasesym_max_WL3_N5,)  129.372978\n",
            "77                (phasef_phasesym_range_WL3_N5,)  129.372978\n",
            "154                        (tf_Gabor_0.2A0.0max,)  129.075343\n",
            "107  (tf_GLRLM_RunLengthNonUniformityNormalized,)  122.988680\n",
            "161                      (tf_Gabor_0.2A0.79mean,)  122.141871\n",
            "141                     (tf_Gabor_0.05A1.57kurt,)  116.225170\n",
            "158                        (tf_Gabor_0.2A0.0std,)  113.279741\n",
            "153                       (tf_Gabor_0.2A0.0kurt,)  112.503449\n",
            "142                      (tf_Gabor_0.05A1.57max,)  110.258146\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/_univariate_selection.py:114: UserWarning: Features [207 210 211 212] are constant.\n",
            "  UserWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/_univariate_selection.py:115: RuntimeWarning: invalid value encountered in true_divide\n",
            "  f = msb / msw\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4GWUil5e___A",
        "colab_type": "code",
        "outputId": "ad41daa6-9491-46a2-8fb9-cbb333cbc935",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        }
      },
      "source": [
        "# Random Forest Classifier\n",
        "\n",
        "# Set parameters\n",
        "parameters = {\"n_estimators\": list(range(1, 20, 2))}\n",
        "    # nog een range kiezen\n",
        "\n",
        "scores = ['precision']\n",
        "\n",
        "for score in scores:\n",
        "    print('# Random Forest Classifier')\n",
        "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
        "    print()\n",
        "    rfc = RandomForestClassifier()\n",
        "    grid_search = GridSearchCV(\n",
        "        rfc, parameters, scoring='%s_macro' % score\n",
        "    ) \n",
        "    # cv is nu default, dus een kfold van 5! \n",
        "    grid_search.fit(X_train_scaled, y_train)\n",
        "\n",
        "    print(\"Best parameters set found on development set:\")\n",
        "    print()\n",
        "    clf = grid_search.best_estimator_\n",
        "    best_parameters = grid_search.best_params_\n",
        "    print(best_parameters)\n",
        "    print()\n",
        "    print(\"Grid score on development set:\")\n",
        "    print()\n",
        "    score = grid_search.best_score_\n",
        "    print(score)\n",
        "    print()\n",
        "\n",
        "# test data\n",
        "print(\"# Evaluate with test data set\")\n",
        "y_true, y_pred = y_test, clf.predict(X_test_scaled)\n",
        "\n",
        "auc=metrics.roc_auc_score(y_true, y_pred)\n",
        "print(f'AUC:{auc}')\n",
        "accuracy=metrics.accuracy_score(y_true, y_pred)\n",
        "print(f'accuracy:{accuracy}')\n",
        "F1=metrics.f1_score(y_true,y_pred)\n",
        "print(f'F1:{F1}')\n",
        "precision=metrics.precision_score(y_true,y_pred)\n",
        "print(f'precision:{precision}')\n",
        "recall=metrics.recall_score(y_true, y_pred)\n",
        "print(f'recall:{recall}')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# Random Forest Classifier\n",
            "# Tuning hyper-parameters for precision\n",
            "\n",
            "Best parameters set found on development set:\n",
            "\n",
            "{'n_estimators': 13}\n",
            "\n",
            "Grid score on development set:\n",
            "\n",
            "0.7951344181193831\n",
            "\n",
            "# Evaluate with test data set\n",
            "AUC:0.718194426932291\n",
            "accuracy:0.7431906614785992\n",
            "F1:0.7975460122699386\n",
            "precision:0.7558139534883721\n",
            "recall:0.8441558441558441\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TuutfCjs6Rjq",
        "colab_type": "code",
        "outputId": "e28a68ec-5dc2-4045-fb7d-40ba9abd89e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        }
      },
      "source": [
        "# Support Vector Machine Classifier\n",
        "\n",
        "# Set parameters\n",
        "parameters = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-2],\n",
        "                     'C': [1, 10]}]\n",
        "\n",
        "scores = ['precision']\n",
        "\n",
        "for score in scores:\n",
        "    print('# Support Vector Machine Classifier')\n",
        "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
        "    print()\n",
        "    svc = SVC()\n",
        "    grid_search = GridSearchCV(\n",
        "        svc, parameters, scoring='%s_macro' % score\n",
        "    ) \n",
        "    # cv is nu default, dus een kfold van 5! \n",
        "    grid_search.fit(X_train_scaled, y_train)\n",
        "\n",
        "    print(\"Best parameters set found on development set:\")\n",
        "    print()\n",
        "    clf = grid_search.best_estimator_\n",
        "    best_parameters = grid_search.best_params_\n",
        "    print(best_parameters)\n",
        "    print()\n",
        "    print(\"Grid score on development set:\")\n",
        "    print()\n",
        "    score = grid_search.best_score_\n",
        "    print(score)\n",
        "    print()\n",
        "\n",
        "# test data\n",
        "print(\"# Evaluate with test data set\")\n",
        "y_true, y_pred = y_test, clf.predict(X_test_scaled)\n",
        "\n",
        "auc=metrics.roc_auc_score(y_true, y_pred)\n",
        "print(f'AUC:{auc}')\n",
        "accuracy=metrics.accuracy_score(y_true, y_pred)\n",
        "print(f'accuracy:{accuracy}')\n",
        "F1=metrics.f1_score(y_true,y_pred)\n",
        "print(f'F1:{F1}')\n",
        "precision=metrics.precision_score(y_true,y_pred)\n",
        "print(f'precision:{precision}')\n",
        "recall=metrics.recall_score(y_true, y_pred)\n",
        "print(f'recall:{recall}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# Support Vector Machine Classifier\n",
            "# Tuning hyper-parameters for precision\n",
            "\n",
            "Best parameters set found on development set:\n",
            "\n",
            "{'C': 1, 'gamma': 0.001, 'kernel': 'rbf'}\n",
            "\n",
            "Grid score on development set:\n",
            "\n",
            "0.8133525181627007\n",
            "\n",
            "# Evaluate with test data set\n",
            "AUC:0.7797251292396923\n",
            "accuracy:0.7976653696498055\n",
            "F1:0.8375\n",
            "precision:0.8072289156626506\n",
            "recall:0.8701298701298701\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SDDcjSKdCSnu",
        "colab_type": "code",
        "outputId": "23d1bfae-9c49-40a9-d66d-03d1e4664f8b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        }
      },
      "source": [
        "# K Nearest Neighbour Classifier\n",
        "\n",
        "# Set parameters\n",
        "parameters = {\"n_neighbors\": list(range(1, 50, 2))}\n",
        "\n",
        "scores = ['precision']\n",
        "\n",
        "for score in scores:\n",
        "    print(\"# K Nearest Neighbour Classifier\")\n",
        "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
        "    print()\n",
        "    knn = KNeighborsClassifier()\n",
        "    grid_search = GridSearchCV(\n",
        "        knn, parameters, scoring='%s_macro' % score\n",
        "    ) \n",
        "    # cv is nu default, dus een kfold van 5! \n",
        "    grid_search.fit(X_train_scaled, y_train)\n",
        "\n",
        "    print(\"Best parameters set found on development set:\")\n",
        "    print()\n",
        "    clf = grid_search.best_estimator_\n",
        "    best_parameters = grid_search.best_params_\n",
        "    print(best_parameters)\n",
        "    print()\n",
        "    print(\"Grid score on development set:\")\n",
        "    print()\n",
        "    score = grid_search.best_score_\n",
        "    print(score)\n",
        "    print()\n",
        "    \n",
        "\n",
        "# test data\n",
        "print('# Evaluate with test data set')\n",
        "y_true, y_pred = y_test, clf.predict(X_test_scaled)\n",
        "\n",
        "auc=metrics.roc_auc_score(y_true, y_pred)\n",
        "print(f'AUC:{auc}')\n",
        "accuracy=metrics.accuracy_score(y_true, y_pred)\n",
        "print(f'accuracy:{accuracy}')\n",
        "F1=metrics.f1_score(y_true,y_pred)\n",
        "print(f'F1:{F1}')\n",
        "precision=metrics.precision_score(y_true,y_pred)\n",
        "print(f'precision:{precision}')\n",
        "recall=metrics.recall_score(y_true, y_pred)\n",
        "print(f'recall:{recall}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# K Nearest Neighbour Classifier\n",
            "# Tuning hyper-parameters for precision\n",
            "\n",
            "Best parameters set found on development set:\n",
            "\n",
            "{'n_neighbors': 49}\n",
            "\n",
            "Grid score on development set:\n",
            "\n",
            "0.8044034857691911\n",
            "\n",
            "# Evaluate with test data set\n",
            "AUC:0.7376749464128104\n",
            "accuracy:0.7665369649805448\n",
            "F1:0.8192771084337349\n",
            "precision:0.7640449438202247\n",
            "recall:0.8831168831168831\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}