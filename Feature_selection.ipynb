{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Feature_selection.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOIKi0EiKi3ofAkiLDjg1By",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LauraSchellekens/TM10007_-private_-group/blob/Manon_feature_selection/Feature_selection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QYtLq3tdzJQe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Code for feature selection\n",
        "'''\n",
        "First determine the best amount of features\n",
        "'''\n",
        "\n",
        "# Create the RFE object and compute a cross-validated score.\n",
        "svc = svm.SVC(kernel=\"linear\")\n",
        "X= \n",
        "y= \n",
        "\n",
        "# classifications\n",
        "rfecv = feature_selection.RFECV(\n",
        "    estimator=svc, step=1, \n",
        "    cv=model_selection.StratifiedKFold(4),\n",
        "    scoring='roc_auc')\n",
        "rfecv.fit(X, y)\n",
        "\n",
        "# Plot number of features VS. cross-validation scores\n",
        "plt.figure()\n",
        "plt.xlabel(\"Number of features selected\")\n",
        "plt.ylabel(\"Cross validation score (nb of correct classifications)\")\n",
        "plt.plot(range(1, len(rfecv.grid_scores_) + 1), rfecv.grid_scores_)\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HijFXdeGgjTd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Code for feature selection\n",
        "'''\n",
        "With the amount of features desired known, find the best performing features\n",
        "'''\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import chi2\n",
        "\n",
        "X = data.iloc[:,0:261]  #independent columns, after preprocessing there are 261 columns left\n",
        "y = y_train    #label, target column \n",
        "#apply SelectKBest class to extract top ... best features\n",
        "bestfeatures = SelectKBest(score_func=chi2, k=10) # k= number of desired features\n",
        "fit = bestfeatures.fit(X,y)\n",
        "dfscores = pd.DataFrame(fit.scores_)\n",
        "dfcolumns = pd.DataFrame(X.columns)\n",
        "#concat two dataframes for better visualization \n",
        "featureScores = pd.concat([dfcolumns,dfscores],axis=1)\n",
        "featureScores.columns = ['Specs','Score']  #naming the dataframe columns\n",
        "print(featureScores.nlargest(10,'Score'))  #print ... best features "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}